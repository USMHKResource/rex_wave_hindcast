{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NREL Wave Hindacast Data Access Via rex\n",
    "\n",
    "#### This notebook demonstrates basic usage of REsource eXtraciton tool (rex) with the National Renewable Energy Laboratory (NREL) West Coast Wave Hindcast dataset. The data is provided from Amazon Web Services using the HDF Group's Highly Scalable Data Service (HSDS).\n",
    "\n",
    "#### For this example to work, the packages necessary can be installed via pip:\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "#### Next you'll need to configure h5pyd to access the data on HSDS:\n",
    "\n",
    "hsconfigure\n",
    "\n",
    "#### and enter at the prompt:\n",
    "\n",
    "hs_endpoint = https://developer.nrel.gov/api/hsds   \n",
    "hs_username = None   \n",
    "hs_password = None   \n",
    "hs_api_key = 3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf    \n",
    "\n",
    "#### The example API key here is for demonstation and is rate-limited per IP. To get your own API key, visit https://developer.nrel.gov/signup/\n",
    "\n",
    "#### You can also add the above contents to a configuration file at ~/.hscfg\n",
    "\n",
    "#### Finally, you can use Jupyter Notebook or Lab to view the example notebooks depending on your preference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import ResourceX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "\n",
    "rex enables the efficient and scalable extraction, manipulation, and computation with NRELs flagship renewable resource datasets: the Wind Integration National Dataset (WIND Toolkit), and the National Solar Radiation Database (NSRDB). Development of functionality with the Wave Hindcast dataset is currently ongoing.\n",
    "\n",
    "The Wave Hindcast Dataset is provided in annual .h5 files and currently spans the Western Coastal Region of the Lower 48 from 1979-2010.\n",
    "\n",
    "Each year can be accessed from /nrel/us-wave/US_Wave_${year}.h5\n",
    "\n",
    "To open the desired year of Wave Hindcast data server endpoint, username, password is found via a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveFile = f'/nrel/us-wave/US_Wave_1990.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick View of meta data and time_index\n",
    "\n",
    "with ResourceX(waveFile, hsds=True) as waves:\n",
    "    meta = waves.meta\n",
    "    time_index = waves.time_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Each dataset quantity:\n",
    "\n",
    "- directionality_coefficient\n",
    "- energy_period\n",
    "- maximum_energy_direction\n",
    "- mean_absolute_period\n",
    "- mean_zero-crossing_period\n",
    "- omni-directional_wave_power\n",
    "- peak_period\n",
    "- significant_wave_height\n",
    "- spectral_width\n",
    "- water_depth\n",
    "\n",
    "is structured as ('time_index','coordinate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes of datasets\n",
    "with ResourceX(waveFile, hsds=True) as waves:\n",
    "    waves['significant_water_height'].shape # (time_index, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the available dataset variable names within the dataset\n",
    "with ResourceX(waveFile, hsds=True) as waves:\n",
    "    print(waves['coordinates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage\n",
    "\n",
    "The following examples illustrate basic spatial and timeseries based slicing techniques for the West Coast Wave Hindcast dataset, along with simple statistical analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Datasets\n",
    "\n",
    "Basic examples to access data via rex. Datasets are returned as Pandas objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries closest to a coordinate pair\n",
    "\n",
    "with ResourceX(waveFile, hsds=True) as f:\n",
    "    lat_lon = (44.624076,-124.280097)\n",
    "    parameters = 'significant_water_height'\n",
    "    swh_single = f.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of latitude/longitude pairs can be passed to extract data from multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ResourceX(waveFile, hsds=True) as f:\n",
    "    lat_lon = [(44.624076,-124.280097),(43.489171,-125.152137)]\n",
    "    parameters = 'significant_water_height'\n",
    "    swh_multi = f.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all data within a State line defined region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ResourceX(waveFile, hsds=True) as f:\n",
    "    region = 'Oregon'\n",
    "    region_col = 'jurisdiction'\n",
    "    variables = 'significant_water_height'\n",
    "    swh_map = f.get_region_df(variables, region, region_col=region_col)\n",
    "swh_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
